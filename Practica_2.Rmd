---
title: "Practica_2"
author: "Norberto García Marín y María Soledad Pérez López"
date: "January 14, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introducción
El proyecto a realizar trata de un estudio entre una red MLP convencional y una red de convolución. Se realizara una comparación con la ayuda de un conjunto de datos: CIFAR-10.

Nuestra red convolucional está formada por dos tipos de capas: convolución y pooling. Gracias a esto deberíamos obtener mejores resultados durante el aprendizaje en compración con la red MLP, especificamente en el accuracy.

En los siguientes apartados se estudiara el funcionamientos de las tecnicas mecionadas ateriormente y se compraran los resultados para ver si se cumples nuestras suposiciones sobre el funcionamiento.



# Librerias necesarias 
```{r}
library(caret)
library(keras)
install_keras(tensorflow = "1.5")

```



# Conjunto CIFAR-10
Se cargan los datos y se muestran

```{r}
set.seed(12345)
dswsize = 10000
dsevalwsize = 2000
c <- dataset_cifar10()
cifar10 <- c
dssize = 50000
mask = sample(1:dssize,dswsize)
cifar10$train$x = cifar10$train$x[mask,,,]
cifar10$train$y = cifar10$train$y[mask,]
dssizeeval = 10000
mask = sample(1:dssizeeval,dsevalwsize)
cifar10$test$x = cifar10$test$x[mask,,,]
cifar10$test$y = cifar10$test$y[mask,]
str(cifar10)
```

Con esto hemos creado el modelo de datos. Se puede ver que hay dos conjuntos: train y test. El conjunto de entrenamiento esta formado por 1000 muestras y tiene imágenes de 32 x 32 (dimesiones) y 3 canales de color RGB, mientras que el test está formado por 2000 muestras.


Se muestran los ejemplos que hay por clase en el conjunto train

```{r}
barplot(table(cifar10$train$y),main="Proporción de tipos de imágenes en cifar10 (training data)",
        xlab="Tipos de imágenes")
```


Y en el conjunto test
```{r}
barplot(table(cifar10$test$y),main="Proporción de tipos de imágenes en cifar10 (test data)",
        xlab="Tipos de imágenes")
```

Se puede observar que existe una proporcionalidad similar entre los ejemplos de ambos conjuntos



Se aplica una transformación a los conjuntos.

```{r}
x_train <- cifar10$train$x
y_train <- cifar10$train$y
x_test <- cifar10$test$x
y_test <- cifar10$test$y
```


Y ahora hacemos reshape para generar arrays en el formato que usará R. R alamacena las cosas de forma lineal, por lo que la matriz genera 3072 índices, que son las dimensiones del array.

```{r}
x_train = array_reshape(x_train,c(nrow(x_train), 3072))
x_test = array_reshape(x_test,c(nrow(x_test), 3072))
```

Seguidamente, comprobamos la separabilidad de los objetos usando un grafico PCA. Se usa el grafico PCA el conjunto test y se colorea cada digito en funcion del ejemplar a representar.

```{r}
n = 10000
pca = prcomp(t(x_train[mask,]))
cols = rainbow(10)
colors = cols[1 + y_train[mask]]
plot(pca$rotation[,1],pca$rotation[,2],col=colors,pch=19,
     xlab="1er PCA",ylab="2o PCA",main=paste0("PCA plot, ",n," imágenes cifar10"))
legend("topright",fill=cols,
       title="Tipos de imágenes",
       col=cols,
       legend=0:9,cex=0.6)
```


Ahora normalizamos los colores en [0,1] dividiendo entre el valor 255, que seriá el maximo, para el conjunto x_train y x_test

```{r}
max(x_train)
max(x_test)
x_train <- x_train / 255
x_test <- x_test / 255
```



Se convierten en datos categoricos y_train y y_test
```{r}
str(y_train)
y_train[1]
y_train[3]
y_train <- to_categorical(y_train, 10)
y_test <- to_categorical(y_test, 10)
str(y_train)
y_train[1,]
y_train[3,]
```

Un tipo de imagen 1 se codifica de la forma: 0 1 0 0 0 0 0 0 0.


# MLP Convencional
Primero debemos crear nuestro modelo secuencial. Las capas de red se definen desde la entrada a la salida, definiendo así la dirección del flujo de datos. Este modelo está definido por capas y la salida de una pasa a las entradas de las siguientes mediante una tubería.

```{r}
model = keras_model_sequential()
model %>%
  layer_dense(units = 32, input_shape = c(3072)) %>%
  layer_activation('relu') %>%
  layer_dense(units = 10) %>%
  layer_activation('softmax')
```

Para empezar, la primera capa toma las entradas de los datos training y test, que generarn vectores de 3072 componentes por entrada. A parte, la capa de salida devuelve 10 posibles salidas, que corresponde a cada tipo de imagen en cuestión.

Además cada nodo de la capa oculta introduce un sesgo que contiene un peso.

En la capa oculta, la función sigmoide recopila información sobre todo pixel de la figura y los procesa.
En la capa de la salida, la función softmax convierte toda la información entre la capa oculta y la de salida en una distribución de probabilidades para los 10 tipos de imágenes.

Por otra parte, en el modelo secuencial se hara uso del operador %% para poder añadir en orden las capas. Se usara layer_dense para conectar los nodos de una capa anterior con la siguiente.



Lanzamos el algoritmo como hemos explicado antes. Vamos a probar distintos hiperparametros para observar sus resultados. Primero cambioamos el tamaño del bach.

```{r}
bsize = c(16,32,64,128,256,512,1024)
nepochs = 50
h = 50
accvvals = NULL
acctvals = NULL
h_final = 16
acc = 0
for(b in bsize){
    set.seed(12345)
    #Conectamos todos los nodos de la capa anterior con los de la siguiente
    model = keras_model_sequential()
    model %>%
      layer_dense(units = h, activation = 'sigmoid', input_shape = c(3072)) %>%
      layer_dense(units = 10, activation = 'softmax')
    
    #Compilamos el modelo
    model %>% compile(
      loss = 'categorical_crossentropy',
      optimizer = 'adam',
      metrics = c('accuracy')
    )
    
    #Entrenamos el modelo
    history = model %>% fit(
      x_train, y_train,
      epochs = nepochs,
      batch_size = b,
      validation_split = 0.2,
      verbose = 0
    )
    
    cat("Los errores de entrenamiento y evaluación para",b,"batch size son", history$metrics$loss[nepochs],"y",history$metrics$val_loss[nepochs],"\n")
    cat("Valores de accuracy de entrenamiento y evaluación para",b,"batch size son", history$metrics$acc[nepochs],"y",history$metrics$val_acc[nepochs],"\n")
    accvvals = c(accvvals,history$metrics$val_acc[nepochs])
    acctvals = c(acctvals,history$metrics$acc[nepochs])
    if(history$metrics$val_acc[nepochs]>acc){
      acc = history$metrics$val_acc[nepochs]
      b_final = b
    }
}
ymin = min(c(accvvals,acctvals))
plot(y=acctvals,x=bsize,ylab="Accuracy",xlab="batch size",main="Valores de accuracy para entrenamiento/test a través de tamaños de batch",col="blue",ylim=c(ymin,1),type="l")
lines(x=bsize,y=accvvals,col="red")
```

A continuación cambiamos el número de nodos ocultos.

```{r}
nhidden = c(48,96,192,256,512)
bsize = b_final
nepochs = 50
accvvals = NULL
acctvals = NULL
h_final = 48
acc = 0
for(h in nhidden){
  set.seed(12345)
  model = keras_model_sequential()
  model %>%
    layer_dense(units = h, activation = 'sigmoid', input_shape = c(3072)) %>%
    layer_dense(units = 10, activation = 'softmax')
  model %>% compile(
    loss = 'categorical_crossentropy',
    optimizer = 'adam',
    metrics = c('accuracy')
  )
  history = model %>% fit(
    x_train, y_train,
    epochs = nepochs,
    batch_size = bsize,
    validation_split = 0.2,
    verbose = 0
  )
  cat("Los errores de entrenamiento y evaluación para",h,"nodos son", history$metrics$loss[nepochs],"y", history$metrics$val_loss[nepochs],"\n")
  cat("Los valores de accuracy de entrenamiento y evaluación para",h,"nodos son",history$metrics$acc[nepochs],"y",  history$metrics$val_acc[nepochs],"\n")
  accvvals = c(accvvals,history$metrics$val_acc[nepochs])
  acctvals = c(acctvals,history$metrics$acc[nepochs])
  if(history$metrics$val_acc[nepochs]>acc){
    acc = history$metrics$val_acc[nepochs]
    h_final = h
  }
}
ymin = min(c(accvvals,acctvals))
plot(y=acctvals,x=nhidden,ylab="Accuracy",xlab="nodos ocultos",main="Valores de accuracy para entrenamiento/test a través epochs",col="blue",ylim=c(ymin,1),type="l")
lines(x=nhidden,y=accvvals,col="red")
```

```{r}
cat("Finalmente, los hiperparámetros escogidos son: bach size",b_final,"y número de nodos ocultos", h_final)
```

## Overfitting MLP
El ovverfitting ocurre cuando el Backprpagation se dedica a ajustar la red a pequeñas particularidades locales en elos datos de entrenamien, irrelevantes para el problema general.

Lanzamos la nueva red con los parámetros finales.

```{r}
set.seed(12345)
  model = keras_model_sequential()
  model %>%
    layer_dense(units = h_final, activation = 'sigmoid', input_shape = c(3072)) %>%
    layer_dense(units = 10, activation = 'softmax')
  model %>% compile(
    loss = 'categorical_crossentropy',
    optimizer = 'adam',
    metrics = c('accuracy')
  )
  history = model %>% fit(
    x_train, y_train,
    epochs = nepochs,
    batch_size = b_final,
    validation_split = 0.2,
    verbose = 0
  )
```

Mostramos graficamente los errores de entranamiento y validación a lo largo de los epochs

```{r}
vymax = max(c(history$metrics$loss,history$metrics$val_loss))
plot(history$metrics$loss,main="Erores de entrenamiendo/validación para cifar10",col="blue", type="l",xlab="Epochs",ylab="Loss",ylim=c(0,vymax))
lines(history$metrics$val_loss,col="red")
```

Vemos en los resultados que el error de validación empeora tras un núero de epochs concreto. Por lo que hemos cometido overfitting.


Aplicamos varias técnicas para tratar el overfitting

### L1
#ref =https://towardsdatascience.com/l1-and-l2-regularization-methods-ce25e7fc831c
La tecnica L1 de regularización o tambien llamada Lasso Regression, límita la capacidad de la red actuando en su algoritmo de entranamiento, añadiendo en la funcion de perdida un coeficiente de penaliación en función de sus valores abosultos.


```{r}
model_b = keras_model_sequential()
model_b %>%
  layer_dense(units = h_final,
              kernel_regularizer = regularizer_l1(0.001),
              input_shape = c(3072)) %>%
  layer_activation("sigmoid") %>%
  layer_dense(units = 10) %>%
  layer_activation("softmax")
summary(model_b)

model_b %>% compile(
  loss = 'categorical_crossentropy',
  optimizer = 'adam',
  metrics = c('accuracy')
)

history_b = model_b %>% fit(
  x_train, y_train,
  epochs = 50,
  batch_size = b_final,
  validation_split = 0.2,
  verbose = 0)
```


###L2

La técina L2 de regularización o también llamada Ridge Regression. Es una técnica muy parecida a L1 pero esta utiliza los cuadrados en lugar de los valores absolutos.

```{r}
model_c = keras_model_sequential()
model_c %>%
  layer_dense(units = h_final,
              #Podemos usar regularizer_l1, regularizer_l2
              #y regularizer_l1_l2
              kernel_regularizer = regularizer_l2(0.001),
              input_shape = c(3072)) %>%
  layer_activation("sigmoid") %>%
  layer_dense(units = 10) %>%
  layer_activation("softmax")
summary(model_c)

model_c %>% compile(
  loss = 'categorical_crossentropy',
  optimizer = 'adam',
  metrics = c('accuracy')
)
history_c = model_c %>% fit(
  x_train, y_train,
  epochs = 50,
  batch_size = b_final,
  validation_split = 0.2,
  verbose = 0)

```

### Dropout
Esta tecnica consiste en establecer a 0 una fracción del input (establecida al 50%) en cada actualización durante el proceso de entrenamiento, con lo que conseguimos prevenir el overfitting.

```{r}
model_d = keras_model_sequential()
model_d %>%
  layer_dense(units = h_final, activation="sigmoid",
              input_shape = c(3072)) %>%
  layer_dropout(rate=0.5) %>%
  layer_dense(units = 10,activation="softmax") %>%
  summary(model_d)

model_d %>% compile(
  loss = 'categorical_crossentropy',
  optimizer = 'adam',
  metrics = c('accuracy')
)
history_d = model_d %>% fit(
  x_train, y_train,
  epochs = 50,
  batch_size = b_final,
  validation_split = 0.2,
  verbose = 0)
```




Y ahora comparamos los distintos modelos

```{r}
vymax = max(c(history$metrics$loss,
              history$metrics$val_loss,
              history_b$metrics$loss,
              history_b$metrics$val_loss,
              history_c$metrics$loss,
              history_c$metrics$val_loss,
              history_d$metrics$loss,
              history_d$metrics$val_loss))
plot(history$metrics$loss,main="Training/Validation errors for small cifar10",col="blue",
     type="l",xlab="Epochs",ylab="Loss",ylim=c(1.5,vymax))
lines(history$metrics$val_loss,col="red")
lines(history_b$metrics$loss,col="green")
lines(history_b$metrics$val_loss,col="darkgreen")
lines(history_c$metrics$loss,col="cyan")
lines(history_c$metrics$val_loss,col="darkblue")
lines(history_d$metrics$loss,col="darkviolet")
lines(history_d$metrics$val_loss,col="darkred")
legend("topright",fill=c("blue","red","green","darkgreen",
                         "cyan","darkblue","darkviolet","darkred"),
       title="Regularizaciones",
       col=c("blue","red","green","darkgreen",
             "cyan","darkblue","darkviolet","darkred"),
       legend=c("Training (no reg)",
                "Validation (no reg)",
                "Training (L1)",
                "Validation (L1)",
                "Training (L2)",
                "Validation (L2)",
                "Training (Dropout)",
                "Validation (Dropout)"),cex=0.5)
```


Evaluamos con el conjunto test

```{r}
results = NULL
results[["noreg"]] = evaluate(model,x_test,y_test)
results[["l1"]] = evaluate(model_b,x_test,y_test)
results[["l2"]] = evaluate(model_c,x_test,y_test)
results[["dropout"]] = evaluate(model_d,x_test,y_test)
accs = unlist(lapply(results,function(x){ return(x$acc)}))
barplot(accs,
        main="Accuracy",names.arg=names(results))
print(accs)
```


### Crossvalidación para comprobar los resultados
Despues de corregir el overfiting hay que asegurrar que el modelo mantiene el acurracy mostrado, y para esto utilizamos crossvalidación.
Es una tecnica utilizada para evaluar los resultados y garantizar que son idenpendientes de la partición entre el conjunt train y test.


```{r}
set.seed(12345)
k=5
nepochs = 50
folds = createFolds(y=cifar10$train$y,k=k)
allindex = 1:length(cifar10$train$y)
accs = accsdrop = NULL
for(i in 1:k){
  eval_index = folds[[i]]
  train_index = allindex[!(allindex %in% eval_index)]
  cat("\nTrabajando en el pliegue",i,"con",length(train_index),"ejemplos de entrenamiento y",length(eval_index),"ejemplos de evaluación\n")
  model_a = keras_model_sequential()
  model_a %>%
    layer_dense(units = h_final, activation = 'sigmoid', input_shape = c(3072)) %>%
    layer_dense(units = 10, activation = 'softmax')
  summary(model_a)
  model_a %>% compile(
    loss = 'categorical_crossentropy',
    optimizer = 'adam',
    metrics = c('accuracy')
  )
  history = model_a %>% fit(
    x = x_train[train_index,],
    y = y_train[train_index,],
    validation_data = list(x_train[eval_index,],y_train[eval_index,]),
    epochs = nepochs,
    batch_size = b_final,
    validation_split = 0.0,
    verbose = 0
  )
  cat("Nuevo accuracy para MLP, pliegue",i,"=",history$metrics$val_acc[nepochs],"\n")
  accs = c(accs,history$metrics$val_acc[nepochs])
  model_d = keras_model_sequential()
  model_d %>%
    layer_dense(units = h_final, activation="sigmoid",
    input_shape = c(3072)) %>%
    layer_dropout(rate=0.5) %>%
    layer_dense(units = 10,activation="softmax") %>%
  summary(model_d)
  model_d %>% compile(
    loss = 'categorical_crossentropy',
    optimizer = 'adam',
    metrics = c('accuracy')
  )
  history_d = model_d %>% fit(
    x = x_train[train_index,],
    y = y_train[train_index,],
    validation_data = list(x_train[eval_index,],y_train[eval_index,]),
    epochs = nepochs,
    batch_size = 1024,
    validation_split = 0.0,
    verbose = 0)
  cat("Nuevo accuracy MLP + dropout, pliegue",i,"=",history_d$metrics$val_acc[nepochs],"\n")
  accsdrop = c(accsdrop,history_d$metrics$val_acc[nepochs])
}
cat("El accuracy para MLP es",mean(accs),"\n")
cat("El accuracy para MLP + dropout es",mean(accsdrop),"\n")
```





# 2. Red de convolución

## Tratamiento de datos

```{r}
# Conjunto de datos
seed(12345)
dswsize = 10000
dsevalwsize = 2000
cifar10 <- dataset_cifar10()
dssize = 50000
mask = sample(1:dssize,dswsize)
cifar10$train$x = cifar10$train$x[mask,,,]
cifar10$train$y = cifar10$train$y[mask,]
dssizeeval = 10000
mask = sample(1:dssizeeval,dsevalwsize)
cifar10$test$x = cifar10$test$x[mask,,,]
cifar10$test$y = cifar10$test$y[mask,]
```


```{r}
# Preparación de datos
batch_size <- 128
num_classes <- 10
nepochs <- 20

# Dimensiones de la imagen
img_rows <- 32
img_cols <- 32

```

Obtenemos los conjuntos de entrenamiento y de evaluación.

```{r}

train_x <- cifar10$train$x
train_y <- cifar10$train$y
test_x <- cifar10$test$x
test_y <- cifar10$test$y

train_x <- array_reshape(train_x, c(nrow(train_x), img_rows, img_cols, 4))
test_x <- array_reshape(test_x, c(nrow(test_x), img_rows, img_cols, 4))
input_shape <- c(img_rows, img_cols, 4)

# Normalizamos los colores en 0 y 1
train_x <- train_x / 255
test_x <- test_x / 255

cat('x_train_shape:', dim(train_x), '\n')
cat(nrow(train_x), 'train samples\n')
cat(nrow(test_x), 'test samples\n')

# Convert class vectors to binary class matrices
train_y <- to_categorical(train_y, num_classes)
test_y <- to_categorical(test_y, num_classes)

```


# Definición del modelo


```{r}
nhidden = c(48,96,192)
acc2 = 0
h_final2 = 48
accvvals2 = NULL
acctvals2 = NULL

for(h in nhidden){
  model2 <- keras_model_sequential()
  model2 %>%
    layer_conv_2d(filters = 32, kernel_size = c(4,4), activation = 'relu',input_shape = input_shape) %>% 
    layer_conv_2d(filters = 64, kernel_size = c(4,4), activation = 'relu') %>% 
    layer_max_pooling_2d(pool_size = c(2, 2)) %>% 
    layer_dropout(rate = 0.25) %>% 
    layer_flatten() %>% 
    layer_dense(units = h, activation = 'relu') %>% 
    layer_dropout(rate = 0.5) %>% 
    layer_dense(units = num_classes, activation = 'softmax')
  
  model2 %>% compile(
    loss = loss_categorical_crossentropy,
    optimizer = 'adam',
    metrics = c('accuracy')
  )
  summary(model2)
  
  history2 = model2 %>% fit(
    train_x, train_y,
    batch_size = batch_size,
    epochs = nepochs,
    verbose = 0,
    validation_data = list(test_x, test_y)
  )
  
  scores2 <- model2 %>% evaluate(test_x, test_y, verbose = 0)
  
  
  cat("Los errores de entrenamiento y evaluación para ",h," nodos son ", history2$metrics$loss[nepochs], " y ", history2$metrics$val_loss[nepochs],"\n")
  cat("Los valores de accuracy de entrenamiento y evaluación para ",h," nodos son ", history2$metrics$acc[nepochs], " y ", history2$metrics$val_acc[nepochs],"\n")
  
  accvvals2 = c(accvvals2,history2$metrics$val_acc[nepochs])
  acctvals2 = c(acctvals2,history2$metrics$acc[nepochs])
  if(history2$metrics$val_acc[nepochs]>acc2){
    acc2 = history2$metrics$val_acc[nepochs]
    h_final2 = h
  }
}

ymin = min(c(accvvals2,acctvals2))
plot(y=acctvals2,x=nhidden,ylab="Accuracy",xlab="hidden nodes",main="Acuracy train/test a trav?s de epochs",col="blue",ylim=c(ymin,1),type="l")
lines(x=nhidden,y=accvvals2,col="red")
```


```{r}
bsize = c(256,512,1024)
h = h_final2
acc = 0
b_final2 = 16
acc2 = 0
accvvals2 = NULL
acctvals2 = NULL
for(b in bsize){
  model2 <- keras_model_sequential()
  model2 %>%
    layer_conv_2d(filters = 32, kernel_size = c(4,4), activation = 'relu',input_shape = input_shape) %>% 
    layer_conv_2d(filters = 64, kernel_size = c(4,4), activation = 'relu') %>% 
    layer_max_pooling_2d(pool_size = c(2, 2)) %>% 
    layer_dropout(rate = 0.25) %>% 
    layer_flatten() %>% 
    layer_dense(units = h, activation = 'relu') %>% 
    layer_dropout(rate = 0.5) %>% 
    layer_dense(units = num_classes, activation = 'softmax')
  
  model2 %>% compile( loss = loss_categorical_crossentropy, optimizer = 'adam', metrics = c('accuracy') )
  summary(model2)
  
  history2 = model2 %>% fit(
    train_x, train_y,
    batch_size = b,
    epochs = nepochs,
    verbose = 0,
    validation_data = list(test_x, test_y)
  )
  scores2 <- model2 %>% evaluate(
    test_x, test_y, verbose = 0
  )
  cat("Los errores de entrenamiento y evaluación para ", b, " batch size son " , history2$metrics$loss[nepochs]," y ", history2$metrics$val_loss[nepochs], "\n")
  cat("Los valores de accuracy de entrenamiento y evaluación para ", b, " batch size son ", history2$metrics$acc[nepochs], " y ", history2$metrics$val_acc[nepochs], "\n")
  
  accvvals2 = c(accvvals2,history2$metrics$val_acc[nepochs])
  acctvals2 = c(acctvals2,history2$metrics$acc[nepochs])
  
  if(history2$metrics$val_acc[nepochs]>acc2){
    acc2 = history2$metrics$val_acc[nepochs]
    b_final2 = b
  }
}

ymin = min(c(accvvals2,acctvals2))
plot(y=acctvals2, x=bsize, ylab="Accuracy", xlab="batch size", main="Valores accuracy entrenamiento/test batch size", col="blue", ylim=c(ymin,1), type="l")
lines(x=bsize, y=accvvals2, col="red")
```

```{r}
cat("Hiperparámetros elegidos: bach size",b_final2," y número de nodos ocultos", h_final2)
```



## Crossvalidación para la red

```{r}
k=5
folds = createFolds(y=cifar10$train$y,k=k)
allindex = 1:length(cifar10$train$y)
accs = accsdrop = NULL
for(i in 1:k){
   eval_index = folds[[i]]
   train_index = allindex[!(allindex %in% eval_index)]
   cat("Trabajando en el pliegue ",i," con ",length(train_index), " ejemplos de entrenamiento y ", length(eval_index),
       " ejemplos de evaluación\n")
   
   model <- keras_model_sequential()
   model %>%
     layer_conv_2d(filters = 32, kernel_size = c(4,4), activation = 'relu',
                   input_shape = input_shape) %>%
     layer_conv_2d(filters = 64, kernel_size = c(4,4), activation = 'relu') %>%
     layer_max_pooling_2d(pool_size = c(2, 2)) %>%
     layer_dropout(rate = 0.25) %>%
     layer_flatten() %>%
     layer_dense(units = h_final2, activation = 'relu') %>%
     layer_dropout(rate = 0.5) %>%
     layer_dense(units = num_classes, activation = 'softmax')
   
   summary(model)
   model %>% compile( loss = loss_categorical_crossentropy, optimizer = 'adam', metrics = c('accuracy') )
   
   history = model %>% fit( train_x, train_y, batch_size=b_final2, epochs=nepochs, verbose=0,
                            validation_data=list(train_x[eval_index,,,], train_y[eval_index,])
   )
  cat("Nuevo accuracy para CNN, pliegue",i,"=",history$metrics$val_acc[nepochs],"\n")
  accsdrop = c(accsdrop, history$metrics$val_acc[nepochs])
}
cat("El accuracy para la CNN con dropout es",mean(accsdrop),"\n")
```

